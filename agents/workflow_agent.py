# agents/workflow_agent.py - Comentado Linha a Linha

# Agente Workflow - Pesquisa estruturada e an√°lise comparativa
# Coment√°rio descritivo: define especializa√ß√£o em workflows estruturados

import os
# M√≥dulo padr√£o para intera√ß√£o com sistema operacional

import json
# M√≥dulo para manipula√ß√£o de dados JSON
# Usado para serializa√ß√£o/deserializa√ß√£o de estruturas complexas

from typing import Dict, Any, List, Optional
# Type hints para melhor documenta√ß√£o e type safety

# Imports para workflow estruturado
from langgraph.graph import StateGraph, END
# StateGraph: grafo de estados para workflows complexos
# END: n√≥ terminal que finaliza execu√ß√£o do workflow
# Conceito: State Machine para fluxos determin√≠sticos

from langchain_openai import ChatOpenAI
# Integra√ß√£o com modelos OpenAI via LangChain

from langchain_core.messages import HumanMessage, SystemMessage
# Tipos de mensagem padronizados do LangChain
# HumanMessage: entrada do usu√°rio
# SystemMessage: instru√ß√µes do sistema

# Imports dos modelos Pydantic
from pydantic import BaseModel
# Framework para valida√ß√£o de dados e modelos tipados
# Benef√≠cios: valida√ß√£o autom√°tica, serializa√ß√£o, type safety

# Carregamento de vari√°veis
from dotenv import load_dotenv
# Carregamento de configura√ß√£o de arquivo .env

# Biblioteca Firecrawl
from firecrawl import FirecrawlApp
# SDK oficial para API Firecrawl
# Abstra√ß√£o de alto n√≠vel para web scraping

# Carrega vari√°veis de ambiente
load_dotenv()
# Execu√ß√£o do carregamento de configura√ß√µes


# ===============================
# MODELOS PYDANTIC
# ===============================
# Se√ß√£o organizacional: agrupa defini√ß√µes de modelos de dados

class CompanyAnalysis(BaseModel):
    """Modelo para an√°lise estruturada de empresa/produto"""
    # Pydantic model para dados estruturados de an√°lise
    # BaseModel: classe base que fornece valida√ß√£o e serializa√ß√£o
    
    pricing_model: str
    # Campo obrigat√≥rio: modelo de precifica√ß√£o da empresa
    # str: tipo string obrigat√≥rio
    
    is_open_source: Optional[bool] = None
    # Campo opcional: indica se √© open source
    # Optional[bool]: pode ser True, False ou None
    # Default None: valor padr√£o quando n√£o especificado
    
    tech_stack: List[str] = []
    # Lista de tecnologias utilizadas
    # List[str]: lista de strings
    # Default []: lista vazia como padr√£o
    
    description: str = ""
    # Descri√ß√£o textual da empresa/produto
    # Default "": string vazia como padr√£o
    
    api_available: Optional[bool] = None
    # Indica disponibilidade de API
    # Pattern repetido: Optional para dados incertos
    
    language_support: List[str] = []
    # Linguagens de programa√ß√£o suportadas
    # Lista vazia por padr√£o
    
    integration_capabilities: List[str] = []
    # Capacidades de integra√ß√£o com outras ferramentas
    # Pattern consistente: listas vazias por padr√£o


class CompanyInfo(BaseModel):
    """Modelo completo para informa√ß√µes de empresa"""
    # Modelo mais abrangente que inclui CompanyAnalysis
    
    name: str
    # Nome da empresa (campo obrigat√≥rio)
    
    description: str
    # Descri√ß√£o da empresa (campo obrigat√≥rio)
    
    website: str
    # URL do website oficial (campo obrigat√≥rio)
    
    pricing_model: Optional[str] = None
    # Modelo de pre√ßos (opcional, pode n√£o estar dispon√≠vel)
    
    is_open_source: Optional[bool] = None
    # Indica licenciamento open source
    
    tech_stack: List[str] = []
    # Stack tecnol√≥gico utilizado
    
    competitors: List[str] = []
    # Lista de concorrentes identificados
    
    api_available: Optional[bool] = None
    # Disponibilidade de API p√∫blica
    
    language_support: List[str] = []
    # Suporte a linguagens de programa√ß√£o
    
    integration_capabilities: List[str] = []
    # Integra√ß√µes suportadas
    
    developer_experience_rating: Optional[str] = None
    # Avalia√ß√£o da experi√™ncia do desenvolvedor
    # String para permitir ratings qualitativos


class ResearchState(BaseModel):
    """Modelo para estado global do workflow"""
    # State object para workflow LangGraph
    # Mant√©m estado atrav√©s das etapas do workflow
    
    query: str
    # Consulta original do usu√°rio (imut√°vel)
    
    extracted_tools: List[str] = []
    # Ferramentas extra√≠das de artigos
    # Resultado da primeira etapa do workflow
    
    companies: List[CompanyInfo] = []
    # Informa√ß√µes coletadas das empresas
    # Resultado da etapa de pesquisa
    
    search_results: List[Dict[str, Any]] = []
    # Resultados brutos de busca
    # Dict[str, Any]: estrutura flex√≠vel para dados de APIs
    
    analysis: Optional[str] = None
    # An√°lise final e recomenda√ß√µes
    # Resultado da √∫ltima etapa do workflow


# ===============================
# PROMPTS ORGANIZADOS
# ===============================
# Se√ß√£o organizacional: centraliza prompts em classe

class DeveloperToolsPrompts:
    """Container para prompts organizados por categoria"""
    # Design pattern: namespace para prompts
    # Vantagem: organiza√ß√£o, reutiliza√ß√£o, manuten√ß√£o
    
    # Tool extraction prompts
    TOOL_EXTRACTION_SYSTEM = """Voc√™ √© um pesquisador de pre√ßos, promo√ß√µes, ofertas e valores. Extraia nomes espec√≠ficos de ferramentas, bibliotecas, plataformas ou servi√ßos de artigos.
Concentre-se em produtos/ferramentas/solu√ß√µes/servi√ßos reais que consumidores demonstrem interesse e podem usar."""
    # System prompt para extra√ß√£o de ferramentas
    # Define persona: pesquisador especializado
    # Foco: produtos comercializ√°veis para consumidores

    @staticmethod
    def tool_extraction_user(query: str, content: str) -> str:
        # Static method: n√£o precisa de inst√¢ncia da classe
        # Template function: gera prompt personalizado
        return f"""Query: {query}
Conte√∫do do Artigo: {content}

Extraia uma lista de nomes de produtos/ferramentas/solu√ß√µes/servi√ßos espec√≠ficos mencionados neste conte√∫do que sejam relevantes para "{query}".

Rules:
- Incluir apenas nomes de produtos reais, sem termos gen√©ricos
- Foco em ferramentas/solu√ß√µes/servi√ßos que os consumidores podem comprar, obter, assinar, usar e consumir diretamente
- Incluir op√ß√µes comerciais e de c√≥digo aberto
- Limitar √†s 5 resultados mais relevantes
- Retornar apenas os nomes dos produtos/ferramentas/solu√ß√µes/servi√ßos, um por linha, sem descri√ß√µes

Formato de exemplo:
Amazon
MercadoLivre
Picpay
Nubank
Microsoft
"""
        # Template detalhado com:
        # 1. Context injection (query + content)
        # 2. Instru√ß√µes espec√≠ficas
        # 3. Constraints (5 resultados, formato espec√≠fico)
        # 4. Examples para few-shot learning

    # Company analysis prompts
    TOOL_ANALYSIS_SYSTEM = """Voc√™ est√° analisando pre√ßos, promo√ß√µes, ofertas e valores de produtos/ferramentas/solu√ß√µes/servi√ßos com base na categoria informada pelo usu√°rio.
Concentre-se em extrair informa√ß√µes relevantes para consumidores de produtos/ferramentas/solu√ß√µes/servi√ßos.
Preste aten√ß√£o especial nas condi√ß√µes, descontos, modelo comercial, pr√©-requisitos, tecnologia, APIs, SDKs e modos de utiliza√ß√£o."""
    # System prompt para an√°lise de empresas
    # Foca em aspectos comerciais e t√©cnicos relevantes

    @staticmethod
    def tool_analysis_user(company_name: str, content: str) -> str:
        # Template para an√°lise individual de empresa
        return f"""Empresa/Ferramenta: {company_name}
Conte√∫do do Website: {content[:2500]}

Analise este conte√∫do da perspectiva de um consumidor e forne√ßa:
- pricing_model: "Gratuito", "Freemium", "Pago", "Empresarial", "Assinatura" ou "Desconhecido"
- is_open_source: verdadeiro se for de c√≥digo aberto, falso se for propriet√°rio, nulo se n√£o estiver claro
- tech_stack: tecnologia adotada para produtos/ferramentas/solu√ß√µes/servi√ßos oferecido
- description: breve descri√ß√£o de uma frase com foco no que esta produtos/ferramentas/solu√ß√µes/servi√ßos entrega para o consumidor
- api_available: verdadeiro se API REST, GraphQL, SDK ou acesso program√°tico forem mencionados
- language_support: Lista de linguagens de programa√ß√£o explicitamente suportadas
- integration_capabilities: Lista de ferramentas/plataformas com as quais se integra
"""
        # Template estruturado que:
        # 1. Limita conte√∫do ([:2500]) para evitar overflow
        # 2. Define campos espec√≠ficos do modelo Pydantic
        # 3. Fornece valores v√°lidos para campos categ√≥ricos
        # 4. Especifica crit√©rios de avalia√ß√£o

    # Recommendations prompts
    RECOMMENDATIONS_SYSTEM = """Voc√™ √© um pesquisador s√™nior que fornece recomenda√ß√µes t√©cnicas r√°pidas e concisas.
Mantenha as respostas breves e pr√°ticas - no m√°ximo 3 a 4 frases no total."""
    # System prompt para gera√ß√£o de recomenda√ß√µes
    # Constraint de brevidade: 3-4 frases
    # Persona: pesquisador s√™nior (autoridade)

    @staticmethod
    def recommendations_user(query: str, company_data: str) -> str:
        # Template para gera√ß√£o de recomenda√ß√µes finais
        return f"""Consumer Query: {query}
Ferramentas/Tecnologias Analisadas: {company_data}

Forne√ßa uma breve recomenda√ß√£o (m√°ximo de 3 a 4 frases) abrangendo:
- Qual ferramenta √© a melhor e por qu√™
- Principais considera√ß√µes sobre custo/pre√ßo
- Principal vantagem t√©cnica
- A melhor oferta, pre√ßos e condi√ß√µes

N√£o s√£o necess√°rias longas explica√ß√µes."""
        # Template focado em:
        # 1. Decis√£o clara (melhor ferramenta)
        # 2. Aspectos financeiros (custo/pre√ßo)
        # 3. Aspectos t√©cnicos (vantagens)
        # 4. Aspectos comerciais (ofertas)


# ===============================
# SERVI√áO FIRECRAWL
# ===============================
# Se√ß√£o organizacional: abstra√ß√£o para servi√ßos externos

class FirecrawlService:
    """Servi√ßo para integra√ß√£o com Firecrawl API"""
    # Service class: encapsula integra√ß√£o com API externa
    # Design pattern: Facade para simplificar uso de API complexa
    
    def __init__(self):
        api_key = os.getenv("FIRECRAWL_API_KEY")
        # Obt√©m chave da API das vari√°veis de ambiente
        
        if not api_key:
            raise ValueError("FIRECRAWL_API_KEY n√£o encontrada")
        # Fail-fast: falha imediatamente se configura√ß√£o inv√°lida
        
        self.app = FirecrawlApp(api_key=api_key)
        # Inicializa cliente Firecrawl com autentica√ß√£o

    def search_companies(self, query: str, num_results: int = 5):
        """Busca empresas/produtos usando Firecrawl"""
        # M√©todo para busca de empresas
        # Default num_results=5: valor padr√£o otimizado
        
        try:
            result = self.app.search(
                query=f"{query} pre√ßos, ofertas e valores",
                # Augmented query: adiciona termos comerciais
                # Melhora relev√¢ncia dos resultados
                limit=num_results
                # Limita quantidade de resultados
            )
            return result
            # Retorna resultado bruto da API
            
        except Exception as e:
            print(f"Erro na busca: {e}")
            # Log do erro para debugging
            return []
            # Retorna lista vazia em caso de erro
            # Graceful degradation: falha n√£o quebra workflow

    def scrape_company_pages(self, url: str):
        """Faz scraping de p√°ginas espec√≠ficas"""
        # M√©todo para scraping de URL espec√≠fica
        
        try:
            result = self.app.scrape_url(
                url,
                formats=["markdown"]
                # Formato markdown: estruturado, f√°cil de processar
                # Preserva hierarquia de conte√∫do
            )
            return result
            # Retorna conte√∫do estruturado
            
        except Exception as e:
            print(f"Erro no scraping: {e}")
            # Log de erro para monitoramento
            return None
            # Retorna None para indicar falha
            # Permite verifica√ß√£o simples: if scraped:


# ===============================
# AGENTE WORKFLOW PRINCIPAL
# ===============================
# Se√ß√£o principal: implementa√ß√£o do agente workflow

class WorkflowAgent:
    """Agente de pesquisa estruturada usando workflows LangGraph"""
    # Classe principal que orquestra todo o processo

    def __init__(self):
        """Inicializa agente com depend√™ncias necess√°rias"""
        
        # Valida√ß√£o de chaves de API
        if not os.getenv("FIRECRAWL_API_KEY"):
            raise ValueError("FIRECRAWL_API_KEY n√£o encontrada")
        # Valida√ß√£o cr√≠tica: sem API key, agente n√£o funciona
        
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY n√£o encontrada")
        # Dupla valida√ß√£o: ambas APIs necess√°rias
        
        # Inicializa servi√ßos
        self.firecrawl = FirecrawlService()
        # Dependency injection: servi√ßo Firecrawl
        
        self.llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.1)
        # LLM com configura√ß√£o otimizada:
        # - gpt-4.1-mini: modelo eficiente
        # - temperature=0.1: quase determin√≠stico, mas com pequena varia√ß√£o
        
        self.prompts = DeveloperToolsPrompts()
        # Namespace de prompts organizados
        
        # Constr√≥i workflow
        self.workflow = self._build_workflow()
        # Inicializa√ß√£o do grafo de estados

    def _build_workflow(self):
        """Constr√≥i workflow como m√°quina de estados"""
        # M√©todo privado para constru√ß√£o do workflow
        # _ prefix: conven√ß√£o Python para m√©todos internos
        
        graph = StateGraph(ResearchState)
        # Cria grafo com ResearchState como tipo do estado
        # StateGraph: framework LangGraph para workflows
        
        # Adiciona n√≥s do workflow
        graph.add_node("extract_tools", self._extract_tools_step)
        # N√≥ 1: extra√ß√£o de ferramentas de artigos
        
        graph.add_node("research", self._research_step)
        # N√≥ 2: pesquisa detalhada de cada ferramenta
        
        graph.add_node("analyze", self._analyze_step)
        # N√≥ 3: an√°lise e gera√ß√£o de recomenda√ß√µes
        
        # Define transi√ß√µes
        graph.set_entry_point("extract_tools")
        # Ponto de entrada: sempre come√ßa por extract_tools
        
        graph.add_edge("extract_tools", "research")
        # Transi√ß√£o linear: extract_tools ‚Üí research
        
        graph.add_edge("research", "analyze")
        # Transi√ß√£o linear: research ‚Üí analyze
        
        graph.add_edge("analyze", END)
        # Fim do workflow: analyze ‚Üí END
        # END: constante que termina execu√ß√£o
        
        return graph.compile()
        # Compila grafo em workflow execut√°vel

    def _extract_tools_step(self, state: ResearchState) -> Dict[str, Any]:
        """Primeiro passo: extrai ferramentas de artigos"""
        # Step function: recebe state, retorna updates
        # Pattern LangGraph: fun√ß√µes puras que modificam estado
        
        print(f"üîç Buscando artigos sobre: {state.query}")
        # UX feedback: informa progresso ao usu√°rio
        # Emoji visual: melhora experi√™ncia

        # Busca artigos relevantes
        article_query = f"{state.query} compara√ß√£o de melhores alternativas"
        # Query augmentation: adiciona termos para encontrar compara√ß√µes
        
        search_results = self.firecrawl.search_companies(article_query, num_results=3)
        # Busca 3 artigos (suficiente para extra√ß√£o, n√£o excessivo)

        # Extrai conte√∫do dos artigos
        all_content = ""
        # Acumulador de conte√∫do
        
        if hasattr(search_results, 'data') and search_results.data:
            # Defensive programming: verifica estrutura de dados
            
            for result in search_results.data:
                # Itera sobre resultados da busca
                
                url = result.get("url", "")
                # Safe access: get() com default vazio
                
                scraped = self.firecrawl.scrape_company_pages(url)
                # Scraping do conte√∫do da p√°gina
                
                if scraped and hasattr(scraped, 'markdown'):
                    # Verifica se scraping foi bem-sucedido
                    
                    all_content += scraped.markdown[:1500] + "\n\n"
                    # Adiciona conte√∫do limitado (1500 chars por artigo)
                    # Evita overflow de contexto

        # Usa LLM para extrair ferramentas
        messages = [
            SystemMessage(content=self.prompts.TOOL_EXTRACTION_SYSTEM),
            # System message: instru√ß√£o base
            
            HumanMessage(content=self.prompts.tool_extraction_user(state.query, all_content))
            # Human message: prompt espec√≠fico com dados
        ]

        try:
            response = self.llm.invoke(messages)
            # Chama LLM com mensagens
            
            tool_names = [
                name.strip()
                for name in response.content.strip().split("\n")
                if name.strip()
            ]
            # Parse da resposta:
            # 1. split("\n"): separa por linhas
            # 2. strip(): remove espa√ßos
            # 3. if name.strip(): filtra linhas vazias
            
            print(f"Ferramentas encontradas: {', '.join(tool_names[:5])}")
            # Feedback visual: mostra ferramentas encontradas
            # [:5]: limita exibi√ß√£o a 5 primeiras
            
            return {"extracted_tools": tool_names}
            # Retorna update para o estado do workflow
            
        except Exception as e:
            print(f"Erro na extra√ß√£o: {e}")
            # Log de erro
            return {"extracted_tools": []}
            # Retorna lista vazia em caso de erro
            # Graceful degradation

    def _analyze_company_content(self, company_name: str, content: str) -> CompanyAnalysis:
        """Analisa conte√∫do de empresa usando structured output"""
        # M√©todo auxiliar para an√°lise individual
        # Structured output: garante formato consistente
        
        structured_llm = self.llm.with_structured_output(CompanyAnalysis)
        # LangChain feature: for√ßa output em formato Pydantic
        # Benef√≠cio: valida√ß√£o autom√°tica, type safety

        messages = [
            SystemMessage(content=self.prompts.TOOL_ANALYSIS_SYSTEM),
            HumanMessage(content=self.prompts.tool_analysis_user(company_name, content))
        ]
        # Pattern consistente: system + human message

        try:
            analysis = structured_llm.invoke(messages)
            # LLM retorna objeto CompanyAnalysis v√°lido
            return analysis
            
        except Exception as e:
            print(f"Erro na an√°lise: {e}")
            # Log de erro para debugging
            
            return CompanyAnalysis(
                pricing_model="Desconhecido",
                is_open_source=None,
                tech_stack=[],
                description="An√°lise falhou",
                api_available=None,
                language_support=[],
                integration_capabilities=[]
            )
            # Fallback object: valores padr√£o em caso de erro
            # Permite workflow continuar mesmo com falhas parciais

    def _research_step(self, state: ResearchState) -> Dict[str, Any]:
        """Segundo passo: pesquisa detalhada de cada ferramenta"""
        # Step 2 do workflow: investiga√ß√£o aprofundada
        
        extracted_tools = getattr(state, "extracted_tools", [])
        # Safe access: getattr com default []

        # Fallback se n√£o extraiu ferramentas
        if not extracted_tools:
            print("Fazendo busca direta...")
            # UX feedback: informa mudan√ßa de estrat√©gia
            
            search_results = self.firecrawl.search_companies(state.query, num_results=4)
            # Busca direta com query original
            
            if hasattr(search_results, 'data') and search_results.data:
                tool_names = [
                    result.get("metadata", {}).get("title", result.get("title", "Unknown"))
                    for result in search_results.data
                ]
                # Extrai t√≠tulos dos resultados
                # Nested get(): acesso seguro a estrutura aninhada
                # Fallback chain: metadata.title ‚Üí title ‚Üí "Unknown"
            else:
                tool_names = []
                # Lista vazia se busca falhar
        else:
            tool_names = extracted_tools[:4]
            # Limita a 4 ferramentas para evitar sobrecarga

        print(f"üî¨ Pesquisando: {', '.join(tool_names)}")
        # Feedback visual com emoji cient√≠fico

        companies = []
        # Lista para acumular informa√ß√µes das empresas
        
        for tool_name in tool_names:
            # Itera sobre cada ferramenta para pesquisa individual
            
            # Busca site oficial
            tool_search_results = self.firecrawl.search_companies(
                tool_name + " site oficial", num_results=1
            )
            # Query espec√≠fica: nome + "site oficial"
            # num_results=1: apenas resultado mais relevante

            if hasattr(tool_search_results, 'data') and tool_search_results.data:
                # Verifica se busca retornou resultados
                
                result = tool_search_results.data[0]
                # Pega primeiro (e √∫nico) resultado
                
                url = result.get("url", "")
                # Extrai URL do resultado

                company = CompanyInfo(
                    name=tool_name,
                    description=result.get("markdown", ""),
                    website=url
                )
                # Cria objeto CompanyInfo b√°sico
                # Pydantic validation: garante tipos corretos

                # Scraping detalhado
                scraped = self.firecrawl.scrape_company_pages(url)
                # Extrai conte√∫do completo da p√°gina
                
                if scraped and hasattr(scraped, 'markdown'):
                    # Verifica sucesso do scraping
                    
                    content = scraped.markdown
                    # Obt√©m conte√∫do em markdown
                    
                    analysis = self._analyze_company_content(company.name, content)
                    # An√°lise usando LLM com structured output

                    # Atualiza informa√ß√µes
                    company.pricing_model = analysis.pricing_model
                    company.is_open_source = analysis.is_open_source
                    company.tech_stack = analysis.tech_stack
                    company.description = analysis.description
                    company.api_available = analysis.api_available
                    company.language_support = analysis.language_support
                    company.integration_capabilities = analysis.integration_capabilities
                    # Merge de dados: b√°sicos + an√°lise detalhada

                companies.append(company)
                # Adiciona empresa √† lista de resultados

        return {"companies": companies}
        # Retorna lista de empresas para o estado

    def _analyze_step(self, state: ResearchState) -> Dict[str, Any]:
        """Terceiro passo: gera recomenda√ß√µes finais"""
        # Step 3: s√≠ntese e recomenda√ß√µes
        
        print("üìä Gerando recomenda√ß√µes...")
        # Feedback com emoji de an√°lise

        # Serializa dados das empresas
        company_data = ", ".join([
            company.model_dump_json() for company in state.companies
        ])
        # Converte objetos Pydantic em JSON
        # model_dump_json(): serializa√ß√£o Pydantic
        # join(): concatena em string √∫nica

        messages = [
            SystemMessage(content=self.prompts.RECOMMENDATIONS_SYSTEM),
            HumanMessage(content=self.prompts.recommendations_user(state.query, company_data))
        ]
        # Pattern consistente para LLM

        try:
            response = self.llm.invoke(messages)
            # Gera recomenda√ß√µes usando LLM
            return {"analysis": response.content}
            # Retorna an√°lise textual
            
        except Exception as e:
            print(f"Erro nas recomenda√ß√µes: {e}")
            return {"analysis": "N√£o foi poss√≠vel gerar recomenda√ß√µes no momento."}
            # Fallback amig√°vel em caso de erro

    async def process_query(self, query: str) -> str:
        """
        Processa query do usu√°rio usando workflow estruturado
        
        Args:
            query: Consulta do usu√°rio
            
        Returns:
            Resposta formatada com resultados e recomenda√ß√µes
        """
        # M√©todo p√∫blico principal: interface do agente
        
        try:
            # Executa workflow
            initial_state = ResearchState(query=query)
            # Cria estado inicial com query do usu√°rio
            
            final_state = self.workflow.invoke(initial_state)
            # Executa workflow completo: extract ‚Üí research ‚Üí analyze
            # invoke(): m√©todo LangGraph para execu√ß√£o
            
            result = ResearchState(**final_state)
            # Reconstr√≥i objeto tipado a partir do resultado

            # Formata resposta
            response_parts = []
            # Lista para construir resposta formatada
            
            response_parts.append(f"üìã **Resultados para: {query}**\n")
            # Header com query original

            if result.companies:
                # Se encontrou empresas
                
                response_parts.append("üè¢ **Empresas/Ferramentas Encontradas:**\n")
                # Se√ß√£o de empresas
                
                for i, company in enumerate(result.companies, 1):
                    # Enumera empresas (come√ßa em 1)
                    
                    company_info = [
                        f"**{i}. {company.name}**",
                        f"üåê Website: {company.website}",
                        f"üí∞ Pre√ßos: {company.pricing_model or 'N/A'}",
                        f"üìñ Open Source: {'Sim' if company.is_open_source else 'N√£o' if company.is_open_source is False else 'N/A'}"
                    ]
                    # Informa√ß√µes b√°sicas sempre presentes
                    # Ternary complex: trata 3 estados (True/False/None)

                    if company.tech_stack:
                        company_info.append(f"üõ†Ô∏è Tecnologias: {', '.join(company.tech_stack[:3])}")
                    # Mostra tecnologias (m√°ximo 3)

                    if company.language_support:
                        company_info.append(f"üíª Linguagens: {', '.join(company.language_support[:3])}")
                    # Mostra linguagens (m√°ximo 3)

                    if company.api_available is not None:
                        api_status = "‚úÖ Dispon√≠vel" if company.api_available else "‚ùå N√£o dispon√≠vel"
                        company_info.append(f"üîå API: {api_status}")
                    # Status de API com emojis visuais

                    if company.description and company.description != "An√°lise falhou":
                        company_info.append(f"üìù Descri√ß√£o: {company.description}")
                    # Descri√ß√£o se dispon√≠vel e v√°lida

                    response_parts.append("\n".join(company_info) + "\n")
                    # Junta informa√ß√µes da empresa

            if result.analysis:
                response_parts.append(f"üí° **Recomenda√ß√µes:**\n{result.analysis}")
            # Adiciona recomenda√ß√µes se dispon√≠veis

            return "\n".join(response_parts)
            # Junta todas as partes da resposta

        except Exception as e:
            return f"‚ùå Erro ao processar consulta: {str(e)}"
            # Mensagem de erro amig√°vel

    def get_workflow_info(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes sobre o workflow"""
        # M√©todo de introspec√ß√£o: informa√ß√µes sobre capacidades
        
        return {
            "name": "Research Workflow Agent",
            "version": "1.0.0",
            "steps": ["extract_tools", "research", "analyze"],
            "capabilities": [
                "Extra√ß√£o de ferramentas de artigos",
                "Pesquisa detalhada de empresas",
                "An√°lise comparativa",
                "Recomenda√ß√µes t√©cnicas"
            ]
        }
        # Metadados estruturados sobre o agente
        # √ötil para debugging e documenta√ß√£o
