# Imports para type hints - fundamentais para code quality e IDE support
from typing import Dict, Any
# Dict[str, Any]: Especifica dicion√°rio com chaves string e valores de qualquer tipo
# Any: Tipo gen√©rico quando tipo espec√≠fico n√£o pode ser determinado estaticamente

# Core do LangGraph para cria√ß√£o de workflows baseados em grafos
from langgraph.graph import StateGraph, END
# StateGraph: Implementa m√°quina de estados finita para workflows complexos
# END: Constante que indica t√©rmino do workflow (estado final)

# Wrapper LangChain para modelos OpenAI
from langchain_openai import ChatOpenAI
# ChatOpenAI: Abstra√ß√£o padronizada para modelos de chat da OpenAI

# Classes base para mensagens no formato LangChain
from langchain_core.messages import HumanMessage, SystemMessage
# HumanMessage: Representa input do usu√°rio no conversation flow
# SystemMessage: Define comportamento e contexto do assistente

# Imports locais - modelos de dados Pydantic para type safety
from .models import ResearchState, CompanyInfo, CompanyAnalysis
# ResearchState: Estado global do workflow (query, resultados, an√°lise)
# CompanyInfo: Modelo para informa√ß√µes estruturadas de empresa
# CompanyAnalysis: Modelo para an√°lise detalhada de empresa

# Servi√ßo de integra√ß√£o com Firecrawl API
from .firecrawl import FirecrawlService
# FirecrawlService: Encapsula opera√ß√µes de web scraping e search

# Container de prompts organizados por funcionalidade
from .prompts import DeveloperToolsPrompts
# DeveloperToolsPrompts: Classe com templates de prompts para LLM


# Classe principal que orquestra workflow de pesquisa usando padr√£o de m√°quina de estados
class Workflow:
    # Inicializador que configura depend√™ncias e constr√≥i workflow
    def __init__(self):
        # Instancia servi√ßo Firecrawl para web scraping
        self.firecrawl = FirecrawlService()
        # Instancia modelo LLM com configura√ß√µes otimizadas para an√°lise
        self.llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.1)
        # Temperature 0.1 = quase determin√≠stico mas com leve criatividade
        
        # Instancia container de prompts
        self.prompts = DeveloperToolsPrompts()
        # Constr√≥i e compila workflow como grafo de estados
        self.workflow = self._build_workflow()

    # M√©todo privado que define estrutura do workflow como State Machine
    def _build_workflow(self):
        # Cria grafo de estados com ResearchState como estrutura de dados compartilhada
        graph = StateGraph(ResearchState)
        
        # Define n√≥s (estados) do workflow com suas respectivas fun√ß√µes
        graph.add_node("extract_tools", self._extract_tools_step)
        # N√≥ 1: Extrai ferramentas/produtos relevantes de artigos
        graph.add_node("research", self._research_step)
        # N√≥ 2: Pesquisa detalhada de cada ferramenta identificada
        graph.add_node("analyze", self._analyze_step)
        # N√≥ 3: Analisa dados coletados e gera recomenda√ß√µes
        
        # Define ponto de entrada do workflow
        graph.set_entry_point("extract_tools")
        
        # Define transi√ß√µes entre estados (edges do grafo)
        graph.add_edge("extract_tools", "research")
        graph.add_edge("research", "analyze")
        graph.add_edge("analyze", END)
        # Workflow linear: extract ‚Üí research ‚Üí analyze ‚Üí fim
        
        # Compila grafo em executor otimizado
        return graph.compile()

    # Primeiro passo: extrai nomes de ferramentas/produtos de artigos relevantes
    def _extract_tools_step(self, state: ResearchState) -> Dict[str, Any]:
        # Log informativo para tracking do progresso
        print(f"üîç Encontrar artigos sobre: {state.query}")

        # Monta query otimizada para encontrar artigos comparativos
        article_query = f"{state.query} compara√ß√£o de melhores alternativas para produtos/ferramentas/solu√ß√µes/servi√ßos"
        # Busca artigos com limite de 3 para performance
        search_results = self.firecrawl.search_companies(article_query, num_results=3)

        # Concatena conte√∫do de todos os artigos encontrados
        all_content = ""
        for result in search_results.data:
            # Extrai URL do resultado da busca
            url = result.get("url", "")
            # Faz scraping da p√°gina para obter conte√∫do completo
            scraped = self.firecrawl.scrape_company_pages(url)
            if scraped:
                # Limita a 1500 chars por artigo para controle de token
                all_content + scraped.markdown[:1500] + "\n\n"

        # Constr√≥i conversa para LLM com system + user message
        messages = [
            SystemMessage(content=self.prompts.TOOL_EXTRACTION_SYSTEM),
            HumanMessage(content=self.prompts.tool_extraction_user(state.query, all_content))
        ]

        # Bloco try-catch para tratamento robusto de erros LLM
        try:
            # Invoca LLM para extrair nomes de ferramentas
            response = self.llm.invoke(messages)
            # Processa resposta: split por linha e remove espa√ßos
            tool_names = [
                name.strip()
                for name in response.content.strip().split("\n")
                if name.strip()  # Remove linhas vazias
            ]
            # Log dos resultados para debugging
            print(f"Produtos/ferramentas/solu√ß√µes/servi√ßos: {', '.join(tool_names[:5])}")
            # Retorna update para o estado do workflow
            return {"extracted_tools": tool_names}
        except Exception as e:
            # Fallback em caso de erro: continua workflow com lista vazia
            print(e)
            return {"extracted_tools": []}

    # M√©todo para an√°lise detalhada de conte√∫do de empresa usando structured output
    def _analyze_company_content(self, company_name: str, content: str) -> CompanyAnalysis:
        # Configura LLM para retornar output estruturado (Pydantic model)
        structured_llm = self.llm.with_structured_output(CompanyAnalysis)
        # with_structured_output for√ßa LLM a retornar dados no formato do modelo

        # Constr√≥i prompt espec√≠fico para an√°lise de empresa
        messages = [
            SystemMessage(content=self.prompts.TOOL_ANALYSIS_SYSTEM),
            HumanMessage(content=self.prompts.tool_analysis_user(company_name, content))
        ]

        # Tratamento de erro com fallback estruturado
        try:
            # Invoca LLM e for√ßa retorno como CompanyAnalysis
            analysis = structured_llm.invoke(messages)
            return analysis
        except Exception as e:
            print(e)
            # Retorna an√°lise vazia mas v√°lida em caso de erro
            return CompanyAnalysis(
                pricing_model="Unknown",
                is_open_source=None,
                tech_stack=[],
                description="Falhou",
                api_available=None,
                language_support=[],
                integration_capabilities=[],
            )


    # Segundo passo: pesquisa detalhada de cada ferramenta identificada
    def _research_step(self, state: ResearchState) -> Dict[str, Any]:
        # Acessa ferramentas extra√≠das do passo anterior
        extracted_tools = getattr(state, "extracted_tools", [])

        # Estrat√©gia de fallback se extra√ß√£o falhou
        if not extracted_tools:
            print("Nenhuma produtos/ferramentas/solu√ß√µes/servi√ßos extra√≠da encontrada, retornando √† pesquisa direta")
            # Busca direta baseada na query original
            search_results = self.firecrawl.search_companies(state.query, num_results=4)
            # Extrai t√≠tulos como nomes de ferramentas
            tool_names = [
                result.get("metadata", {}).get("title", "Unknown")
                for result in search_results.data
            ]
        else:
            # Usa ferramentas extra√≠das, limitando a 4 para performance
            tool_names = extracted_tools[:4]

        # Log do progresso para tracking
        print(f"Pesquisando produtos/ferramentas/solu√ß√µes/servi√ßos espec√≠ficas: {', '.join(tool_names)}")

        # Lista para acumular informa√ß√µes das empresas
        companies = []
        # Loop para pesquisar cada ferramenta individualmente
        for tool_name in tool_names:
            # Busca site oficial da ferramenta
            tool_search_results = self.firecrawl.search_companies(tool_name + " site oficial", num_results=1)

            # Processa resultado se encontrado
            if tool_search_results:
                # Pega primeiro resultado da busca
                result = tool_search_results.data[0]
                # Extrai URL do site oficial
                url = result.get("url", "")

                # Cria objeto CompanyInfo com dados b√°sicos
                company = CompanyInfo(
                    name=tool_name,
                    description=result.get("markdown", ""),
                    website=url,
                    tech_stack=[],
                    competitors=[]
                )

                # Faz scraping detalhado do site da empresa
                scraped = self.firecrawl.scrape_company_pages(url)
                if scraped:
                    # Obt√©m conte√∫do em markdown
                    content = scraped.markdown
                    # Analisa conte√∫do usando LLM estruturado
                    analysis = self._analyze_company_content(company.name, content)

                    # Atualiza objeto company com an√°lise detalhada
                    company.pricing_model = analysis.pricing_model
                    company.is_open_source = analysis.is_open_source
                    company.tech_stack = analysis.tech_stack
                    company.description = analysis.description
                    company.api_available = analysis.api_available
                    company.language_support = analysis.language_support
                    company.integration_capabilities = analysis.integration_capabilities

                # Adiciona empresa √† lista de resultados
                companies.append(company)

        # Retorna update do estado com empresas pesquisadas
        return {"companies": companies}

    # Terceiro passo: gera an√°lise final e recomenda√ß√µes
    def _analyze_step(self, state: ResearchState) -> Dict[str, Any]:
        # Log do progresso
        print("Gerando recomenda√ß√µes")

        # Serializa dados das empresas para an√°lise LLM
        company_data = ", ".join([
            company.json() for company in state.companies
        ])

        # Constr√≥i prompt para gera√ß√£o de recomenda√ß√µes
        messages = [
            SystemMessage(content=self.prompts.RECOMMENDATIONS_SYSTEM),
            HumanMessage(content=self.prompts.recommendations_user(state.query, company_data))
        ]

        # Invoca LLM para an√°lise final
        response = self.llm.invoke(messages)
        # Retorna an√°lise como string
        return {"analysis": response.content}

    # M√©todo p√∫blico que executa workflow completo
    def run(self, query: str) -> ResearchState:
        # Cria estado inicial com query do usu√°rio
        initial_state = ResearchState(query=query)
        # Executa workflow passando estado inicial
        final_state = self.workflow.invoke(initial_state)
        # Retorna estado final como ResearchState validado
        return ResearchState(**final_state)